{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3de55c",
   "metadata": {},
   "source": [
    "# This notebook is designed for performing inference the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "located-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d27b181",
   "metadata": {},
   "source": [
    "### Read in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "independent-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('submit_samples.csv')\n",
    "\n",
    "id_list_test = sample['mac_hash']\n",
    "\n",
    "id_dict = {m: [] for m in id_list_test}\n",
    "\n",
    "# label_dict\n",
    "label_dict_test = dict()\n",
    "\n",
    "for data in list(test_data.values):\n",
    "    loc = data[1]\n",
    "    id_dict[data[0]].append(loc)\n",
    "\n",
    "for k, v in id_dict.items():\n",
    "    if len(v) != 14:\n",
    "        id_dict[k] = [0] * (14 - len(v)) + v\n",
    "\n",
    "data = np.array(list(id_dict.values()))\n",
    "X_test = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaebf51",
   "metadata": {},
   "source": [
    "### Bert model with pretrained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "posted-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_seq (InputLayer)         [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  40160       ['input_seq[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 14,                                                \n",
      "                                16),                                                              \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 16),                                                           \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 16)          0           ['tf_bert_model[0][0]']          \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           544         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 5)            165         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,869\n",
      "Trainable params: 40,869\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel, BertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config = BertConfig(vocab_size=15, hidden_size=16, num_hidden_layer=8, num_attention_heads=4,\n",
    "                    intermediate_size=64, max_position_embeddings=14)\n",
    "bert = TFBertModel(config)\n",
    "\n",
    "input_seq = tf.keras.layers.Input(shape=(14,), name='input_seq', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(14,), name='attention_mask', dtype='int32')\n",
    "\n",
    "encoder = bert(input_seq, attention_mask=mask)[0][:,0] \n",
    "\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(encoder)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs=[input_seq, mask], outputs=y)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model_1.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deluxe-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e836f438e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.load_weights('./checkpoint_Bert/Transformer_Bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd59469",
   "metadata": {},
   "source": [
    "### XLNet model with pretrained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6770a942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_seq (InputLayer)         [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  28672       ['input_seq[0][0]']              \n",
      "                                last_hidden_state=(                                               \n",
      "                                None, 14, 16),                                                    \n",
      "                                 mems=((14, None, 1                                               \n",
      "                                6),                                                               \n",
      "                                 (14, None, 16),                                                  \n",
      "                                 (14, None, 16),                                                  \n",
      "                                 (14, None, 16),                                                  \n",
      "                                 (14, None, 16),                                                  \n",
      "                                 (14, None, 16),                                                  \n",
      "                                 (14, None, 16),                                                  \n",
      "                                 (14, None, 16)),                                                 \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 16)          0           ['tfxl_net_model[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           544         ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 5)            165         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,381\n",
      "Trainable params: 29,381\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetConfig, TFXLNetModel\n",
    "\n",
    "config = XLNetConfig(vocab_size=15, d_model=16, n_layer=8, n_head=4, d_inner=64)\n",
    "\n",
    "xlnet = TFXLNetModel(config)\n",
    "\n",
    "input_seq = tf.keras.layers.Input(shape=(14,), name='input_seq', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(14,), name='attention_mask', dtype='int32')\n",
    "\n",
    "embeddings = xlnet(input_seq)[0]\n",
    "embeddings = embeddings[:, 0]\n",
    "\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)\n",
    "model_2 = tf.keras.Model(inputs=[input_seq, mask], outputs=y)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model_2.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432c34c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e836d30d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.load_weights('./checkpoint_XLNet/Transformer_XLNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094e477",
   "metadata": {},
   "source": [
    "### Test set inference with two different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informed-wages",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_mask = np.ones((len(X_test),14))\n",
    "\n",
    "y_prob_1 = model_1.predict([X_test, X_test_mask])\n",
    "y_prob_2 = model_2.predict([X_test, X_test_mask])\n",
    "\n",
    "y_prob = np.zeros(y_prob_1.shape)\n",
    "for i in range(len(y_prob)):\n",
    "    prob_bert = y_prob_1[i]\n",
    "    prob_xlnet = y_prob_2[i]  \n",
    "    if max(prob_bert) < 0.9 and max(prob_xlnet) > max(prob_bert) and np.argmax(prob_bert) != np.argmax(prob_xlnet) and max(prob_xlnet) > 0.65:\n",
    "        y_prob[i] = prob_xlnet\n",
    "    else:\n",
    "        y_prob[i] = prob_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "difficult-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac_hash</th>\n",
       "      <th>C0</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b882f1d44602a25349a08f4a0af32977</td>\n",
       "      <td>1.644878e-02</td>\n",
       "      <td>3.026091e-03</td>\n",
       "      <td>9.804910e-01</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.014368e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86e644b498922f3a2fd0e6e1a1525de3</td>\n",
       "      <td>6.630775e-09</td>\n",
       "      <td>3.083047e-07</td>\n",
       "      <td>2.422495e-07</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>9.981961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691662b04ee08015062d901a4c5628b1</td>\n",
       "      <td>9.999843e-01</td>\n",
       "      <td>1.428103e-05</td>\n",
       "      <td>9.742126e-09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.203056e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52b5c510a28774237f4f118764c2ed6f</td>\n",
       "      <td>1.278072e-05</td>\n",
       "      <td>9.999846e-01</td>\n",
       "      <td>1.420636e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.989756e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9f3c995e53d109f532056b6eae29a0b5</td>\n",
       "      <td>5.603018e-05</td>\n",
       "      <td>1.705543e-02</td>\n",
       "      <td>9.828635e-01</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>3.136814e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>5001c0dfe522886ed884c0dc4e5848df</td>\n",
       "      <td>9.999769e-01</td>\n",
       "      <td>2.151064e-05</td>\n",
       "      <td>7.950201e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.632553e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>f1c8781e701e89068fa0b8a62ecbc564</td>\n",
       "      <td>1.104203e-08</td>\n",
       "      <td>7.250758e-07</td>\n",
       "      <td>2.572627e-07</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>9.984059e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>646136b402e136422466a2acd8636630</td>\n",
       "      <td>9.999788e-01</td>\n",
       "      <td>1.982054e-05</td>\n",
       "      <td>8.296314e-09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.537372e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>c7bea6491029f86ab3d1f0f9b599ca2c</td>\n",
       "      <td>2.082628e-04</td>\n",
       "      <td>2.273876e-06</td>\n",
       "      <td>9.997736e-01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>7.816325e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>822fd3104f38cc6374f2996d3d6920a2</td>\n",
       "      <td>9.999758e-01</td>\n",
       "      <td>2.247789e-05</td>\n",
       "      <td>7.830447e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.689074e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3429 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mac_hash            C0            C1  \\\n",
       "0     b882f1d44602a25349a08f4a0af32977  1.644878e-02  3.026091e-03   \n",
       "1     86e644b498922f3a2fd0e6e1a1525de3  6.630775e-09  3.083047e-07   \n",
       "2     691662b04ee08015062d901a4c5628b1  9.999843e-01  1.428103e-05   \n",
       "3     52b5c510a28774237f4f118764c2ed6f  1.278072e-05  9.999846e-01   \n",
       "4     9f3c995e53d109f532056b6eae29a0b5  5.603018e-05  1.705543e-02   \n",
       "...                                ...           ...           ...   \n",
       "3424  5001c0dfe522886ed884c0dc4e5848df  9.999769e-01  2.151064e-05   \n",
       "3425  f1c8781e701e89068fa0b8a62ecbc564  1.104203e-08  7.250758e-07   \n",
       "3426  646136b402e136422466a2acd8636630  9.999788e-01  1.982054e-05   \n",
       "3427  c7bea6491029f86ab3d1f0f9b599ca2c  2.082628e-04  2.273876e-06   \n",
       "3428  822fd3104f38cc6374f2996d3d6920a2  9.999758e-01  2.247789e-05   \n",
       "\n",
       "                C2        C3            C4  \n",
       "0     9.804910e-01  0.000034  1.014368e-08  \n",
       "1     2.422495e-07  0.001803  9.981961e-01  \n",
       "2     9.742126e-09  0.000001  2.203056e-12  \n",
       "3     1.420636e-08  0.000003  2.989756e-08  \n",
       "4     9.828635e-01  0.000022  3.136814e-06  \n",
       "...            ...       ...           ...  \n",
       "3424  7.950201e-09  0.000002  2.632553e-12  \n",
       "3425  2.572627e-07  0.001593  9.984059e-01  \n",
       "3426  8.296314e-09  0.000001  2.537372e-12  \n",
       "3427  9.997736e-01  0.000016  7.816325e-10  \n",
       "3428  7.830447e-09  0.000002  2.689074e-12  \n",
       "\n",
       "[3429 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'mac_hash':sample['mac_hash'], 'C0':y_prob[:,0], 'C1':y_prob[:,1], 'C2':y_prob[:,2], 'C3':y_prob[:,3], 'C4':y_prob[:,4]})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broad-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"output_Transformer_Best.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
